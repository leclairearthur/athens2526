{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Work 5: Image Restoration\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "In this practical session, you have to complete the code regions marked ``### ... ###``.\n",
    "\n",
    "Also, you should write some comments in the textual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "pi = torch.pi\n",
    "\n",
    "def rgb2gray(u):\n",
    "    return 0.2989 * u[:,:,0] + 0.5870 * u[:,:,1] + 0.1140 * u[:,:,2]\n",
    "\n",
    "def str2(chars):\n",
    "    return \"{:.2f}\".format(chars)\n",
    "\n",
    "def psnr(uref,ut,M=1):\n",
    "    mse = np.sqrt(np.mean((np.array(uref)-np.array(ut))**2))\n",
    "    return 20*np.log10(M/mse)\n",
    "\n",
    "# viewimage\n",
    "import tempfile\n",
    "import IPython\n",
    "from skimage.transform import rescale\n",
    "\n",
    "def viewimage(im, normalize=True,vmin=0,vmax=1,z=1,order=0,titre='',displayfilename=False):\n",
    "    imin= im.numpy().astype(np.float32)\n",
    "    channel_axis = 2 if len(im.shape)>2 else None\n",
    "    if z!=1:\n",
    "        from skimage.transform import rescale\n",
    "        imin = rescale(imin, z, order=order, channel_axis=channel_axis)\n",
    "    if normalize:\n",
    "        if vmin is None:\n",
    "            vmin = imin.min()\n",
    "        if vmax is None:\n",
    "            vmax = imin.max()\n",
    "        if np.abs(vmax-vmin)>1e-10:\n",
    "            imin = (imin.clip(vmin,vmax)-vmin)/(vmax-vmin)\n",
    "        else:\n",
    "            imin = vmin\n",
    "    else:\n",
    "        imin=imin.clip(0,255)/255\n",
    "    imin=(imin*255).astype(np.uint8)\n",
    "    filename=tempfile.mktemp(titre+'.png')\n",
    "    if displayfilename:\n",
    "        print (filename)\n",
    "    plt.imsave(filename, imin, cmap='gray')\n",
    "    IPython.display.display(IPython.display.Image(filename))\n",
    "\n",
    "\n",
    "# alternative viewimage if the other one does not work:\n",
    "def Viewimage(im,dpi=100,cmap='gray'):\n",
    "    plt.figure(dpi=dpi)\n",
    "    if cmap is None:\n",
    "        plt.imshow(np.array(im))\n",
    "    else:\n",
    "        plt.imshow(np.array(im),cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "!wget https://perso.telecom-paristech.fr/aleclaire/mva/tpdeblur.zip\n",
    "!unzip tpdeblur.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper for gradient descent\n",
    "\n",
    "The following function allows to do a run of gradient descent on a function $f$ given as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim(f,niter=1000,lr=0.1):\n",
    "    u = torch.randn(M,N, requires_grad=True)\n",
    "    optimu = torch.optim.SGD([u], lr=lr)\n",
    "    losslist = []\n",
    "    for it in range(niter):\n",
    "        loss = f(u)\n",
    "        losslist.append(loss.detach())\n",
    "        optimu.zero_grad()\n",
    "        loss.backward()\n",
    "        optimu.step()\n",
    "    return u.detach(),losslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the blurred image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load a clean image that will serve for the whole practical session.\n",
    "\n",
    "We will also load a blur kernel with which we will degrade the image. The goal of this session is to recover the clean image $u_0$ from a degraded version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image as a torch.tensor\n",
    "u0 = torch.tensor(rgb2gray(plt.imread('im/simpson512crop.png')))\n",
    "M,N = u0.shape\n",
    "\n",
    "viewimage(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a blur kernel\n",
    "kt = torch.tensor(np.loadtxt('kernels/kernel8.txt'))\n",
    "# kt = np.loadtxt('kernels/levin7.txt')\n",
    "(m,n) = kt.shape\n",
    "\n",
    "plt.imshow(kt)\n",
    "plt.title('Blur kernel')\n",
    "plt.show()\n",
    "\n",
    "# Embed the kernel in a MxN image, and put center at pixel (0,0)\n",
    "k = torch.zeros((M,N))\n",
    "k[0:m,0:n] = kt/torch.sum(kt)\n",
    "k = torch.roll(k,(-int(m/2),-int(n/2)),(0,1))\n",
    "fk = fft2(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the degraded image \n",
    "$$ u_{\\text{blur}} = k*u_0 + w $$\n",
    "where $w$ is a Gaussian white noise of standard deviation $\\sigma > 0$.\n",
    "\n",
    "You will perform the convolution in Fourier domain (thus, with periodic boundary conditions).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.02\n",
    "\n",
    "### ... ###\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.imshow(ublur,cmap='gray')\n",
    "plt.title('Degraded image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Deblurring\n",
    "\n",
    "Try to deblur the image by a naive method: in order to invert the convolution by $k$, you just divide in Fourier domain by $\\hat{k}$.\n",
    "\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ... ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Deblurring with Tychonov regularization\n",
    "\n",
    "Tychonov deblurring is obtained as the minimal point of the following functional\n",
    "$$ F(u) = \\frac{1}{2} \\|k*u - u_{\\text{blur}}\\|_2^2 + \\frac{\\lambda}{2} \\|\\nabla u\\|_2^2 $$\n",
    "where the squared gradient norm is\n",
    "$$ \\|\\nabla u\\|_2^2 = \\|\\partial_1 u\\|_2^2 + \\|\\partial_2 u\\|_2^2 = \\sum_{(x,y) \\in \\Omega} \\partial_1 u(x,y)^2 + \\partial_2 u(x,y)^2 .$$\n",
    "The parameter $\\lambda > 0$ allows to give more or less weight to the regularization.\n",
    "\n",
    "For the derivatives $\\partial_1 u, \\partial_2 u$, you can use a simple discrete scheme, computed with periodic boundary conditions. (For that, you may use `torch.roll`).\n",
    "\n",
    "\n",
    "- Implement the functional $F$.  ($\\lambda$ will be defined as a global variable `lam`)\n",
    "\n",
    "- Check the convergence of gradient descent by plotting the values of $F(u_n)$ along the iterations. (These values are given as output by `optim`.)\n",
    "\n",
    "- Try to adjust the parameter $\\lambda$. What do you observe when $\\lambda$ is large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the functional with data-fidelity and regularization with weight lam>0.  (lam will be defined as a global variable)\n",
    "def F(u):\n",
    "    ### ... ###\n",
    "\n",
    "\n",
    "lam = 1\n",
    "tau = ### ... ###\n",
    "\n",
    "utych,losslist = ### ... ###\n",
    "\n",
    "plt.figure(dpi=180)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(u0, cmap='gray')\n",
    "plt.title('Original',fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ublur, cmap='gray')\n",
    "plt.title('Blurred \\n PSNR='+str2(psnr(u0,v)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(utych, cmap='gray')\n",
    "plt.title('Linear deblurring \\n PSNR='+str2(psnr(u0,utych)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(losslist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tychonov deblurring can also be computed with filtering, directly in the Fourier domain:\n",
    "\n",
    "$$ \\forall (\\xi,\\zeta) \\in \\Omega, \\quad\n",
    "    \\widehat{u_{\\text{tych}}}(\\xi,\\zeta) = \\frac{\\overline{\\widehat{k}(\\xi,\\zeta)} }{|\\widehat{k}(\\xi,\\zeta)|^2 + \\lambda \\ \\hat{L}(\\xi,\\zeta) } \\ \\widehat{u_{\\text{blur}}}(\\xi,\\zeta) $$\n",
    "where\n",
    "\n",
    "$$\\hat{L}(\\xi,\\zeta) = 4  \\left( \\sin^2 \\left(\\frac{\\pi \\xi}{M} \\right) +  \\sin^2 \\left(\\frac{\\pi \\zeta}{N} \\right) \\right) .$$\n",
    "\n",
    "- Compute Tychonov deblurring with this formula (you can use the predefined arrays below for $\\xi$ and $\\zeta$)\n",
    "- Compare with the result obtained with gradient descent.\n",
    "- Does this formula allow you to better understand what happends when you increase $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = torch.arange(M)\n",
    "ind = (xi>M/2)\n",
    "xi[ind] = xi[ind]-M\n",
    "zeta = torch.arange(N)\n",
    "ind = (zeta>N/2)\n",
    "zeta[ind] = zeta[ind]-N\n",
    "Xi,Zeta = torch.meshgrid(xi,zeta,indexing='ij')\n",
    "\n",
    "### ... ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Deblurring with $\\mathsf{TV}_\\varepsilon$ regularization\n",
    "\n",
    "In the course session, we have defined the smoothed total variation as\n",
    "$$ \\mathsf{TV}_{\\varepsilon}(u)\n",
    "= \\sum_{(x,y) \\in \\Omega} \\sqrt{ \\varepsilon^2 + \\partial_1 u (x,y)^2 + \\partial_2 u (x,y)^2 } \\ .$$\n",
    "where $\\varepsilon > 0$ is a parameter.\n",
    "\n",
    "$\\mathsf{TV}_{\\varepsilon}$-deblurring is obtained as the minimal point of the following functional\n",
    "$$ G(u) = \\frac{1}{2} \\|k*u - u_{\\text{blur}}\\|_2^2 + \\lambda \\mathsf{TV}_{\\varepsilon}(u) $$\n",
    "\n",
    "- Implement $\\mathsf{TV}_{\\varepsilon}$-deblurring. For that, you will need to implement the function $G$ (again, $\\lambda$ and $\\varepsilon$ will be defined as global variables.)\n",
    "\n",
    "- Try adjusting the parameter $\\lambda$. How would you describe the deblurred image when $\\lambda$ is large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(u):\n",
    "    ### ... ###\n",
    "\n",
    "\n",
    "lam = ### ... ###\n",
    "ep = 0.01\n",
    "\n",
    "tau = ### ... ###\n",
    "\n",
    "### ... ###\n",
    "\n",
    "plt.figure(dpi=180)\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(u0, cmap='gray')\n",
    "plt.title('Original',fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ublur, cmap='gray')\n",
    "plt.title('Degraded image',fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(u, cmap='gray')\n",
    "plt.title('TV deblurring \\n PSNR='+str2(psnr(u0,u)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare deblurring results with Tychonov regularization and TV regularization\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(u0, cmap='gray')\n",
    "plt.title('Original',fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(ublur, cmap='gray')\n",
    "plt.title('Degraded image',fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(utych, cmap='gray')\n",
    "plt.title('Linear deblurring \\n PSNR='+str2(psnr(u0,utych)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(utvs, cmap='gray')\n",
    "plt.title('TV deblurring \\n PSNR='+str2(psnr(u0,utvs)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the regularization parameter\n",
    "\n",
    "One way to better understand the setting of the parameter $\\lambda$ is to use an oracle deblurring.\n",
    "\n",
    "It means that, assuming the clean image is available, we will look for the value $\\lambda$ which optimizes the PSNR of the deblurred image w.r.t. the clean image.\n",
    "\n",
    "The hope is that, once we find a value that works well for a given image, it will also work well for many other similar images (e.g. with same range, or similar geometric structures).\n",
    "\n",
    "- By computing $\\mathsf{TV}_{\\varepsilon}$ deblurring with several values of $\\lambda$, find the one that maximizes the PSNR to the clean image.\n",
    "- Compute the final deblurring result for this oracle value of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### ... ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Super-resolution (Bonus)\n",
    "\n",
    "For super-resolution, the forward image model (related to downsampling) writes as\n",
    "$$ u_{\\text{DS}} = (k*u)_{\\downarrow s} + w $$\n",
    "where \n",
    "- $w$ is a white Gaussian noise\n",
    "- $k$ is an anti-aliasing filter\n",
    "- $u \\mapsto u_{\\downarrow s}$ is a downsampling operator with stride $s$\n",
    "\n",
    "In the next cell, implement this forward operator to compute a noisy downsampled version of $u_0$.\n",
    "\n",
    "You can use the given Butterworth filter denoed as `bf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For anti-aliasing, you may use the Butterworth filter of order n and cut-off frequency fc \n",
    "#   given below\n",
    "\n",
    "fc = .45  # cutoff frequency\n",
    "n=20      # order of the filter\n",
    "\n",
    "bf = 1/torch.sqrt(1+(f/fc)**(2*n))\n",
    "\n",
    "xi = torch.arange(M)\n",
    "ind = (xi>M/2)\n",
    "xi[ind] = xi[ind]-M\n",
    "zeta = torch.arange(N)\n",
    "ind = (zeta>N/2)\n",
    "zeta[ind] = zeta[ind]-N\n",
    "Xi,Zeta = torch.meshgrid(xi,zeta,indexing='ij')\n",
    "\n",
    "fbf1 = 1/torch.sqrt(1+(Xi/(M*fc/2))**(2*n))\n",
    "fbf2 = 1/torch.sqrt(1+(Zeta/(N*fc/2))**(2*n))\n",
    "fbf = fbf1*fbf2\n",
    "bf = ifft2(fbf).real\n",
    "\n",
    "viewimage(bf)\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(bf[0,:])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### ... ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, adapt the optimization framework seen in the previous sections in order to address super-resolution.\n",
    "\n",
    "You should find the optimized functional by yourself, and you may choose your regularization function, and set the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ... ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
